{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import optimizers\n",
    "import os\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "frame_filename = sorted(glob.glob(\"./frame_level/Train/*.tfrecord\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_rgb = []\n",
    "#feat_audio = []\n",
    "labels = []\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "frame_lvl_record = frame_filename[-2]\n",
    "start_time = time.time()\n",
    "sess = tf.InteractiveSession()\n",
    "for example in tf.python_io.tf_record_iterator(frame_lvl_record):  \n",
    "    tf_seq_example = tf.train.SequenceExample.FromString(example)\n",
    "    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n",
    "    if n_frames < 120:\n",
    "        continue\n",
    "    labels.append(tf_seq_example.context.feature['labels'].int64_list.value)\n",
    "    rgb_frame = []\n",
    "    #audio_frame = []\n",
    "    # iterate through frames\n",
    "    #for i in range(n_frames):\n",
    "    for i in range(120):\n",
    "        i = int(i*n_frames/120)\n",
    "        rgb_frame.append(tf.cast(tf.decode_raw(tf_seq_example.feature_lists.feature_list['rgb'].feature[i].bytes_list.value[0],tf.uint8), tf.float32).eval())\n",
    "        #audio_frame.append(tf.cast(tf.decode_raw(tf_seq_example.feature_lists.feature_list['audio'].feature[i].bytes_list.value[0],tf.uint8), tf.float32).eval())\n",
    "    \n",
    "    feat_rgb.append(rgb_frame)\n",
    "    #feat_audio.append(audio_frame)\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "sess.close()\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rgb = []\n",
    "for video in feat_rgb:\n",
    "    new_frame = []\n",
    "    for frame in video:\n",
    "        #for i in range(len(img)):\n",
    "        #    img[i] = (img[i] - np.min(img))/(np.max(img) - np.min(img))\n",
    "        new_frame.append(np.reshape(frame, (32, 32, 1)))\n",
    "    new_rgb.append(np.array(new_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for label_list in labels:\n",
    "    label_one_hot = np.zeros(4716)\n",
    "    for label in label_list:\n",
    "        label_one_hot[label] = 1\n",
    "    new_labels.append(label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rgb = np.array(new_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels = np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_data = []\n",
    "for i in range(50):\n",
    "    feed_data.append((new_rgb[i], new_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"frames.npy\", new_rgb)\n",
    "np.save(\"labels.npy\", new_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rgb = np.load(\"frames.npy\")\n",
    "new_labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels = new_labels[4972:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (7,7), strides=(1, 1), activation='relu', \n",
    "                                 padding='same'), input_shape=(120, 32, 32, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=\"he_normal\", activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten())) #flatten feature map into 1 dimension\n",
    "\n",
    "model.add(Dropout(0.2)) #Dropout to prevent overfitting\n",
    "model.add(LSTM(256, return_sequences=False, dropout=0.2))\n",
    "model.add(Dense(4716, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform gradient descent\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def generator():\n",
    "    while 1:\n",
    "        video = []\n",
    "        label = []\n",
    "        for _ in range(32):\n",
    "            i = randint(0, 320)\n",
    "            #yield (np.array(new_rgb[i]), np.array(new_labels[i]))\n",
    "            video.append(new_rgb[i])\n",
    "            label.append(new_labels[i])\n",
    "        yield (np.array(video), np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 582s 53s/step - loss: 26.7735 - acc: 0.1562\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 586s 53s/step - loss: 25.4513 - acc: 0.1875\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 580s 53s/step - loss: 22.5470 - acc: 0.2273\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 580s 53s/step - loss: 20.0837 - acc: 0.1847\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 591s 54s/step - loss: 20.4065 - acc: 0.1903\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 592s 54s/step - loss: 20.0445 - acc: 0.2045\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 590s 54s/step - loss: 18.9169 - acc: 0.1733\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 602s 55s/step - loss: 20.0722 - acc: 0.1705\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 612s 56s/step - loss: 17.4560 - acc: 0.2188\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 612s 56s/step - loss: 18.6893 - acc: 0.1818\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 589s 54s/step - loss: 18.7371 - acc: 0.2358\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 567s 52s/step - loss: 19.4298 - acc: 0.2301\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 570s 52s/step - loss: 19.9176 - acc: 0.1903\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 568s 52s/step - loss: 18.0529 - acc: 0.1989\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 569s 52s/step - loss: 18.7157 - acc: 0.1875\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 567s 52s/step - loss: 19.2592 - acc: 0.1875\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 570s 52s/step - loss: 19.7083 - acc: 0.1989\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-08f95c8e676f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.fit(new_rgb, new_labels, epochs = 5, validation_data = (new_rgb, new_labels))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator(), steps_per_epoch = 11, epochs = 20)\n",
    "#model.fit(new_rgb, new_labels, epochs = 5, validation_data = (new_rgb, new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 86s 262ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(new_rgb, new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.466948561234908, 0.19696969701485201]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for new_label in new_labels:\n",
    "    label = []\n",
    "    for i in range(4716):\n",
    "        if new_label[i] == 1:\n",
    "            label.append(i)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_lrcn_330.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model_lrcn_330.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_file = open('model_adam_0_7_mil.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_adam_0_7_mil.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(new_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = len(labels)\n",
    "for j in range(total):\n",
    "    actual_len = len(labels[j])\n",
    "\n",
    "    temp_list = []\n",
    "    for i in range(len(predicted_labels[j])):\n",
    "        temp_list.append((i, predicted_labels[j][i]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    labels_common = 0\n",
    "    for idx, _ in temp_list[:actual_len]:\n",
    "        if idx in labels[j]:\n",
    "            labels_common += 1\n",
    "    #print(labels_common, actual_len/2)\n",
    "    if labels_common >= actual_len/2:\n",
    "        count += 1\n",
    "        #print(count)\n",
    "print(count*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "#total = len(labels_val)\n",
    "total = 0\n",
    "for j in range(len(labels)):\n",
    "    actual_len = len(labels[j])\n",
    "\n",
    "    temp_list = []\n",
    "    for i in range(len(predicted_labels[j])):\n",
    "        temp_list.append((i, predicted_labels[j][i]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    labels_common = 0\n",
    "    for idx, _ in temp_list[:actual_len]:\n",
    "        if idx in labels[j]:\n",
    "            labels_common += 1\n",
    "    #print(labels_common, actual_len/2)\n",
    "    #if labels_common >= actual_len/2:\n",
    "    count += labels_common\n",
    "    total += actual_len\n",
    "        #print(count)\n",
    "print(count*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_csv(\"vocabulary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid_list = df[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 116]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training set demo\n",
    "k = 10\n",
    "labels[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(vid_ids[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Labels are: \n",
      "Animation\n",
      "PokÃ©mon\n",
      "\n",
      "\n",
      "Predicted Labels are: \n",
      "Game\n",
      "Video game\n",
      "Vehicle\n",
      "Concert\n",
      "\n",
      "\n",
      "Number of labels that were found common : 0 out of 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Labels are: \")\n",
    "for label in labels[k]:\n",
    "    print(vid_list[label])\n",
    "actual_len = len(labels[k])\n",
    "print(\"\\n\\nPredicted Labels are: \")\n",
    "\n",
    "temp_list = []\n",
    "for i in range(len(predicted_labels[k])):\n",
    "    temp_list.append((i, predicted_labels[k][i]))\n",
    "temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "for idx, _ in temp_list[:2*actual_len]:\n",
    "    print(vid_list[idx])\n",
    "    \n",
    "labels_common = 0\n",
    "for idx, _ in temp_list[:2*actual_len]:\n",
    "    if idx in labels[k]:\n",
    "        labels_common += 1\n",
    "print(\"\\n\\nNumber of labels that were found common : \"+str(labels_common) + \" out of \" + str(actual_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_filenames_val = sorted(glob.glob(\"./CS 688/Project/Y8M/video_level/Validate/*.tfrecord\"))\n",
    "\n",
    "vid_ids_val = []\n",
    "labels_val = []\n",
    "mean_rgb_val = []\n",
    "mean_audio_val = []\n",
    "for vfn in video_filenames_val[:3]:\n",
    "    for example in tf.python_io.tf_record_iterator(vfn):\n",
    "        tf_example = tf.train.Example.FromString(example)\n",
    "        vid_ids_val.append(tf_example.features.feature['video_id'].bytes_list.value[0].decode(encoding='UTF-8'))\n",
    "        labels_val.append(tf_example.features.feature['labels'].int64_list.value)\n",
    "        mean_rgb_val.append(tf_example.features.feature['mean_rgb'].float_list.value)\n",
    "        #mean_audio_val.append(tf_example.features.feature['mean_audio'].float_list.value)\n",
    "        \n",
    "new_rgb_val = []\n",
    "for img in mean_rgb_val:\n",
    "    #for i in range(len(img)):\n",
    "    #    img[i] = (img[i] - np.min(img))/(np.max(img) - np.min(img))\n",
    "    new_img = np.reshape(img, (32, 32, 1))\n",
    "    new_rgb_val.append(new_img)\n",
    "    \n",
    "new_rgb_val = np.array(new_rgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels_val = model.predict(new_rgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels_val = []\n",
    "for label_list in labels_val:\n",
    "    label_one_hot = np.zeros(4716)\n",
    "    for label in label_list:\n",
    "        label_one_hot[label] = 1\n",
    "    new_labels_val.append(label_one_hot)\n",
    "new_labels_val = np.array(new_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation set demo\n",
    "k = 12\n",
    "labels_val[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(vid_ids_val[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Actual Labels are: \")\n",
    "for label in labels_val[k]:\n",
    "    print(vid_list[label])\n",
    "actual_len = len(labels_val[k])\n",
    "print(\"\\n\\nPredicted Labels are: \")\n",
    "\n",
    "temp_list = []\n",
    "for i in range(len(predicted_labels_val[k])):\n",
    "    temp_list.append((i, predicted_labels_val[k][i]))\n",
    "temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "for idx, _ in temp_list[:2*actual_len]:\n",
    "    print(vid_list[idx])\n",
    "    \n",
    "labels_common = 0\n",
    "for idx, _ in temp_list[:2*actual_len]:\n",
    "    if idx in labels_val[k]:\n",
    "        labels_common += 1\n",
    "print(\"\\n\\nNumber of labels that were found common : \"+str(labels_common) + \" out of \" + str(actual_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = len(labels_val)\n",
    "for j in range(total):\n",
    "    actual_len = len(labels_val[j])\n",
    "\n",
    "    temp_list = []\n",
    "    for i in range(len(predicted_labels_val[j])):\n",
    "        temp_list.append((i, predicted_labels_val[j][i]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    labels_common = 0\n",
    "    for idx, _ in temp_list[:2*actual_len]:\n",
    "        if idx in labels_val[j]:\n",
    "            labels_common += 1\n",
    "    #print(labels_common, actual_len/2)\n",
    "    if labels_common >= actual_len/2:\n",
    "        count += 1\n",
    "        #print(count)\n",
    "print(count*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "#total = len(labels_val)\n",
    "total = 0\n",
    "for j in range(len(labels_val)):\n",
    "    actual_len = len(labels_val[j])\n",
    "\n",
    "    temp_list = []\n",
    "    for i in range(len(predicted_labels_val[j])):\n",
    "        temp_list.append((i, predicted_labels_val[j][i]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    labels_common = 0\n",
    "    for idx, _ in temp_list[:actual_len]:\n",
    "        if idx in labels_val[j]:\n",
    "            labels_common += 1\n",
    "    #print(labels_common, actual_len/2)\n",
    "    #if labels_common >= actual_len/2:\n",
    "    count += labels_common\n",
    "    total += actual_len\n",
    "        #print(count)\n",
    "print(count*100/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates the Global Average Precision by Google\n",
    "print(\"Global Average Precision for validation Data : \")\n",
    "N = 20\n",
    "gap = 0\n",
    "for i in range(len(labels_val)):\n",
    "    actual_len = len(labels_val[i])\n",
    "    temp_list = []\n",
    "    for j in range(len(predicted_labels_val[i])):\n",
    "        temp_list.append((j, predicted_labels_val[i][j]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    num_pos = min(actual_len, N)\n",
    "\n",
    "    delta_recall = 1.0/num_pos\n",
    "    \n",
    "    ap = 0\n",
    "    labels_common = 0\n",
    "    N = min(actual_len, N)\n",
    "    for j in range(N):\n",
    "        temp_label, _ = temp_list[j]\n",
    "        if temp_label in labels_val[i]: \n",
    "            labels_common += 1\n",
    "        ap += (float(labels_common)*delta_recall)/(j+1)\n",
    "    gap += ap\n",
    "print(gap/len(labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Average Precision for training Data : \n",
      "0.11539186507936507\n"
     ]
    }
   ],
   "source": [
    "#Calculates the Global Average Precision by Google\n",
    "print(\"Global Average Precision for training Data : \")\n",
    "N = 20\n",
    "gap = 0\n",
    "for i in range(len(labels[:201])):\n",
    "    actual_len = len(labels[i])\n",
    "    temp_list = []\n",
    "    for j in range(len(predicted_labels[i])):\n",
    "        temp_list.append((j, predicted_labels[i][j]))\n",
    "    temp_list.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    num_pos = min(actual_len, N)\n",
    "\n",
    "    delta_recall = 1.0/num_pos\n",
    "    \n",
    "    ap = 0\n",
    "    labels_common = 0\n",
    "    N = min(actual_len, N)\n",
    "    for j in range(N):\n",
    "        temp_label, _ = temp_list[j]\n",
    "        if temp_label in labels[i]: \n",
    "            labels_common += 1\n",
    "        ap += (float(labels_common)*delta_recall)/(j+1)\n",
    "    gap += ap\n",
    "print(gap/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
